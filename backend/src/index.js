// @ts-nocheck
// src/index.js
require("dotenv").config();
const express = require("express");
const cors = require("cors");
const dayjs = require("dayjs");
const utc = require("dayjs/plugin/utc");
const timezone = require("dayjs/plugin/timezone");
const { PrismaClient } = require("@prisma/client");
const axios = require("axios");
const OpenAI = require("openai");

// ----- Init libs -----
dayjs.extend(utc);
dayjs.extend(timezone);
axios.defaults.timeout = 15000; // ‚úÖ fixed (defaults)

const app = express();
const prisma = new PrismaClient();
const PORT = Number(process.env.PORT) || 10000;
const NODE_ENV = process.env.NODE_ENV || "development";
const LINE_ACCESS_TOKEN = process.env.LINE_ACCESS_TOKEN || "";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || "" });

// ===== Rate-limit & cache config =====
const { setTimeout: delay } = require("node:timers/promises");
const OPENAI_MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";
const OPENAI_RPM = Number(process.env.OPENAI_RPM || 2);            // ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏•‡∏¥‡∏°‡∏¥‡∏ï‡∏à‡∏£‡∏¥‡∏á‡∏Å‡∏±‡∏ô‡∏û‡∏•‡∏≤‡∏î
const OPENAI_MAX_RETRIES = Number(process.env.OPENAI_MAX_RETRIES || 3);
const ENABLE_AUTO_REPORT = process.env.ENABLE_AUTO_REPORT === "true";

let chain = Promise.resolve();                                      // serialize ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏Ç‡∏≠
let lastCall = 0;
const minGapMs = Math.ceil(60000 / Math.max(1, OPENAI_RPM));

// simple in-memory cache
const aiCache = new Map();                                          // key -> {t, val}
const CACHE_TTL_MS = Number(process.env.AI_CACHE_TTL_MS || 120000);
const cacheKey = (q, l, t, h) =>
  `${q}|${Math.round(l)}|${Math.round(t)}|${Math.round(h)}`;
const getCache = (k) => {
  const v = aiCache.get(k);
  if (!v) return null;
  if (Date.now() - v.t > CACHE_TTL_MS) {
    aiCache.delete(k);
    return null;
  }
  return v.val;
};
const setCache = (k, val) => aiCache.set(k, { t: Date.now(), val });

// ===== Utils =====
function cleanAIResponse(text = "") {
  return String(text)
    .replace(/<think>[\s\S]*?<\/think>/gi, "")
    .replace(/<[^>]+>/g, "")
    .trim();
}

function getLightStatus(light) {
  if (light > 50000) return "‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏±‡∏î‡∏°‡∏≤‡∏Å ‚òÄÔ∏è";
  if (light > 10000) return "‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Åüå§";
  if (light > 5000) return "‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á üå•";
  if (light > 1000) return "‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á üåà";
  if (light > 500) return "‡πÅ‡∏™‡∏á‡∏û‡∏≠‡πÉ‡∏ä‡πâ";
  if (light > 100) return "‡πÅ‡∏™‡∏á‡∏ô‡πâ‡∏≠‡∏¢üåô";
  if (light > 10) return "‡∏°‡∏∑‡∏î‡∏™‡∏•‡∏±‡∏ß üåë";
  return "‡∏°‡∏∑‡∏î‡∏°‡∏≤‡∏Å‡πÜ üï≥Ô∏è";
}

function getTempStatus(temp) {
  if (temp > 35) return "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏£‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å ‚ö†Ô∏è";
  if (temp >= 30) return "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏£‡πâ‡∏≠‡∏ô üî•";
  if (temp >= 25) return "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏≠‡∏∏‡πà‡∏ô‡πÜ üåû";
  if (temp >= 20) return "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏û‡∏≠‡∏î‡∏µ üå§";
  return "‡∏≠‡∏∏‡∏ì‡∏´‡∏π‡∏°‡∏¥‡πÄ‡∏¢‡πá‡∏ô ‚ùÑÔ∏è";
}

function getHumidityStatus(humidity) {
  if (humidity > 85) return "‡∏ä‡∏∑‡πâ‡∏ô‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î üåßÔ∏è";
  if (humidity > 70) return "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ä‡∏∑‡πâ‡∏ô ‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß‡∏ï‡∏±‡∏ß üí¶";
  if (humidity > 60) return "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πâ‡∏ô üå´Ô∏è";
  if (humidity > 40) return "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏ö‡∏≤‡∏¢ ‚úÖ";
  if (humidity > 30) return "‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÅ‡∏´‡πâ‡∏á üí®";
  if (humidity > 20) return "‡πÅ‡∏´‡πâ‡∏á‡∏°‡∏≤‡∏Å ü•µ";
  return "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏´‡πâ‡∏á‡∏°‡∏≤‡∏Å üèúÔ∏è";
}

// ===== OpenAI low-level (kept) =====
async function askOpenAI(prompt) {
  if (!process.env.OPENAI_API_KEY) return "‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OPENAI_API_KEY";
  try {
    if (typeof openai.responses?.create === "function") {
      const resp = await openai.responses.create({
        model: OPENAI_MODEL,
        input: prompt,
        temperature: 0.2,
        store: false,
      });
      return resp.output_text ?? "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö";
    }
    throw new Error("Responses API not available");
  } catch (e1) {
    try {
      if (typeof openai.chat?.completions?.create === "function") {
        const resp = await openai.chat.completions.create({
          model: OPENAI_MODEL,
          temperature: 0.2,
          messages: [{ role: "user", content: prompt }],
        });
        return resp.choices?.[0]?.message?.content ?? "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö";
      }
      throw e1;
    } catch (e2) {
      throw e2;
    }
  }
}

// ===== Rate-limit wrapper =====
function parseRetryAfterMs(err) {
  const h = err?.headers;
  if (!h) return null;
  const get = typeof h.get === "function" ? (k) => h.get(k) : (k) => h[k];
  const raw = get("retry-after-ms") || get("retry-after");
  if (!raw) return null;
  const s = String(raw).trim();
  if (s.endsWith("ms")) return Number(s.replace("ms", "")) || null;
  const sec = Number(s);
  return Number.isFinite(sec) ? sec * 1000 : null;
}

function safeAskOpenAI(prompt) {
  return (chain = chain.then(async () => {
    // spacing ‡∏ï‡∏≤‡∏° RPM
    const now = Date.now();
    const wait = Math.max(0, lastCall + minGapMs - now);
    if (wait > 0) await delay(wait);

    let attempt = 0;
    for (;;) {
      try {
        const out = await askOpenAI(prompt);
        lastCall = Date.now();
        return out;
      } catch (err) {
        if (err?.status !== 429 || attempt >= OPENAI_MAX_RETRIES) throw err;
        attempt++;
        const backoff =
          parseRetryAfterMs(err) ?? Math.min(30000, (2 ** attempt) * 1000 + Math.floor(Math.random() * 800));
        console.warn(`[OpenAI] 429 -> retry in ${backoff}ms (attempt ${attempt})`);
        await delay(backoff);
      }
    }
  }));
}

// ===== High-level helper =====
async function answerWithSensorAI(question, light, temp, humidity) {
  const prompt = `
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå:
- ‡∏Ñ‡πà‡∏≤‡πÅ‡∏™‡∏á: ${light} lux
- ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: ${temp} ¬∞C
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: ${humidity} %
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: "${question}"
‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
  `.trim();

  const key = cacheKey(question, light, temp, humidity);
  const cached = getCache(key);
  if (cached) return cached;

  const out = await safeAskOpenAI(prompt);
  setCache(key, out);
  return out;
}

// ===== Express middlewares =====
app.use(cors());
app.use(express.json());

let lastSensorData = null;

// ===== LINE Reply =====
async function replyToUser(replyToken, message) {
  try {
    const trimmedMessage =
      message.length > 1000 ? message.slice(0, 1000) + "\n...(‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)" : message;
    await axios.post(
      "https://api.line.me/v2/bot/message/reply",
      { replyToken, messages: [{ type: "text", text: trimmedMessage }] },
      { headers: { Authorization: `Bearer ${LINE_ACCESS_TOKEN}`, "Content-Type": "application/json" } }
    );
  } catch (err) {
    console.error("‚ùå LINE reply error:", err?.response?.data || err?.message);
  }
}

async function deletePendingReply(id) {
  try {
    await prisma.pendingReply.delete({ where: { id } });
  } catch (err) {
    console.error("‚ùå ‡∏•‡∏ö PendingReply ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:", err?.response?.data || err?.message);
  }
}

// ===== Webhook =====
app.post("/webhook", async (req, res) => {
  res.sendStatus(200);
  const events = req.body.events || [];
  for (const event of events) {
    if (event?.type === "message" && event?.replyToken && event?.source?.userId) {
      processMessageEvent(event).catch(console.error);
    }
  }
});

async function processMessageEvent(event) {
  const userId = event?.source?.userId;
  const replyToken = event?.replyToken;
  const messageType = event?.message?.type || "unknown";
  const text = messageType === "text" ? event.message.text.trim() : "";

  const existingUser = await prisma.user.findUnique({ where: { userId } });
  if (!existingUser) await prisma.user.create({ data: { userId } });

  const exists = await prisma.pendingReply.findUnique({ where: { replyToken } });
  if (exists) return;

  const created = await prisma.pendingReply.create({
    data: { replyToken, userId, messageType, text: text || "(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)" },
  });

  if (!lastSensorData) {
    await replyToUser(replyToken, "‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå");
    await deletePendingReply(created.id);
    return;
  }

  const { light, temp, humidity } = lastSensorData;
  const lightStatus = getLightStatus(light);
  const tempStatus = getTempStatus(temp);
  const humidityStatus = getHumidityStatus(humidity);

  const shortMsg = `üìä ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î :
- ‡∏Ñ‡πà‡∏≤‡πÅ‡∏™‡∏á: ${light} lux (${lightStatus})
- ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: ${temp} ¬∞C (${tempStatus})
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: ${humidity} % (${humidityStatus})`;

  const presetQuestions = [
    "‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
    "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≤‡∏Å‡∏ú‡πâ‡∏≤‡πÑ‡∏´‡∏°",
    "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡∏û‡∏Å‡∏£‡πà‡∏°‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ö‡πâ‡∏≤‡∏ô‡πÑ‡∏´‡∏°",
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏™‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
  ];

  const normalizedText = text.replace(/\s+/g, " ").trim();
  if (!presetQuestions.includes(normalizedText)) {
    await replyToUser(replyToken, shortMsg);
    await deletePendingReply(created.id);
    return;
  }

  await replyToUser(replyToken, "‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≤‡∏° AI...");

  // ‚úÖ ‡πÉ‡∏ä‡πâ answerWithSensorAI (‡∏°‡∏µ‡∏Ñ‡∏¥‡∏ß/‡πÅ‡∏Ñ‡∏ä)
  const aiText = await answerWithSensorAI(normalizedText, light, temp, humidity);
  const finalText = (aiText || "").trim();
  if (!finalText) {
    await replyToUser(replyToken, "‚ùå ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ");
    await deletePendingReply(created.id);
    return;
  }

  const answer = `${normalizedText}?\n- ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏à‡∏≤‡∏Å AI : ${cleanAIResponse(finalText)}`;

  await axios.post(
    "https://api.line.me/v2/bot/message/push",
    { to: userId, messages: [{ type: "text", text: answer }] },
    { headers: { Authorization: `Bearer ${LINE_ACCESS_TOKEN}`, "Content-Type": "application/json" } }
  );

  await deletePendingReply(created.id);
}

// ===== Sensor Data =====
app.post("/sensor-data", (req, res) => {
  const { light, temp, humidity } = req.body || {};
  if (light !== undefined && temp !== undefined && humidity !== undefined) {
    lastSensorData = { light, temp, humidity };
    res.json({ message: "‚úÖ ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß" });
  } else {
    res.status(400).json({ message: "‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö" });
  }
});

// ===== Latest Sensor =====
app.get("/latest", (_req, res) => {
  if (lastSensorData) res.json(lastSensorData);
  else res.status(404).json({ message: "‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå" });
});

app.post("/ask-ai", async (req, res) => {
  try {
    const { question, light: bLight, temp: bTemp, humidity: bHum } = req.body || {};
    if (!question || typeof question !== "string") {
      return res.status(400).json({ error: "‚ùå missing question" });
    }

    let light, temp, humidity;
    if ([bLight, bTemp, bHum].every((v) => typeof v === "number" && !Number.isNaN(v))) {
      light = bLight;
      temp = bTemp;
      humidity = bHum;
    } else if (lastSensorData) {
      ({ light, temp, humidity } = lastSensorData);
    } else {
      return res
        .status(400)
        .json({ error: "‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô body ‡πÅ‡∏•‡∏∞ server)" });
    }

    // ‡∏¢‡∏¥‡∏á AI (‡∏°‡∏µ‡∏Ñ‡∏¥‡∏ß/‡πÅ‡∏Ñ‡∏ä) ‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á‡∏à‡∏∞ fallback
    try {
      const ai = await answerWithSensorAI(question, light, temp, humidity);
      return res.json({ answer: cleanAIResponse(ai), meta: { source: "openai" } });
    } catch (aiErr) {
      console.error("OpenAI error:", aiErr?.response?.data || aiErr?.message || aiErr);
      const fallback =
        `‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n` +
        `‚Ä¢ ‡πÅ‡∏™‡∏á: ${light} lux (${getLightStatus(light)})\n` +
        `‚Ä¢ ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: ${temp} ¬∞C (${getTempStatus(temp)})\n` +
        `‚Ä¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: ${humidity} % (${getHumidityStatus(humidity)})\n` +
        `‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏£‡πâ‡∏≠‡∏ô/‡∏ä‡∏∑‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏î‡∏∑‡πà‡∏°‡∏ô‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏Å‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏ó`;
      return res.json({ answer: fallback, meta: { source: "fallback" } });
    }
  } catch (err) {
    console.error("ask-ai fatal:", err);
    return res.status(500).json({ error: "ask-ai failed", detail: String(err?.message || err) });
  }
});

// ===== Auto report (gated) =====
if (ENABLE_AUTO_REPORT) {
  setInterval(async () => {
    try {
      if (!lastSensorData) return;
      if (!LINE_ACCESS_TOKEN) return;

      const { light, temp, humidity } = lastSensorData;
      const now = dayjs().tz("Asia/Bangkok");
      const buddhistYear = now.year() + 543;

      const thaiDays = ["‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå", "‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå", "‡∏≠‡∏±‡∏á‡∏Ñ‡∏≤‡∏£", "‡∏û‡∏∏‡∏ò", "‡∏û‡∏§‡∏´‡∏±‡∏™‡∏ö‡∏î‡∏µ", "‡∏®‡∏∏‡∏Å‡∏£‡πå", "‡πÄ‡∏™‡∏≤‡∏£‡πå"];
      const thaiMonths = [
        "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°",
        "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå",
        "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°",
        "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô",
        "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°",
        "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô",
        "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°",
        "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°",
        "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô",
        "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°",
        "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô",
        "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°",
      ];

      const thaiTime = `‡∏ß‡∏±‡∏ô${thaiDays[now.day()]} ‡∏ó‡∏µ‡πà ${now.date()} ${thaiMonths[now.month()]} ‡∏û.‡∏®.${buddhistYear} ‡πÄ‡∏ß‡∏•‡∏≤ ${now.format("HH:mm")} ‡∏ô.`;

      const aiAnswer = cleanAIResponse(
        await answerWithSensorAI("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ", light, temp, humidity)
      );

      const message = `üì° ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ :
üïí ‡πÄ‡∏ß‡∏•‡∏≤ : ${thaiTime}
üí° ‡∏Ñ‡πà‡∏≤‡πÅ‡∏™‡∏á : ${light} lux (${getLightStatus(light)})
üå°Ô∏è ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥ : ${temp} ¬∞C (${getTempStatus(temp)})
üíß ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô : ${humidity} % (${getHumidityStatus(humidity)})
ü§ñ AI : ${aiAnswer}`;

      const users = await prisma.user.findMany();
      for (const u of users) {
        await axios.post(
          "https://api.line.me/v2/bot/message/push",
          { to: u.userId, messages: [{ type: "text", text: message }] },
          { headers: { Authorization: `Bearer ${LINE_ACCESS_TOKEN}`, "Content-Type": "application/json" } }
        );
      }
      console.log(`‚úÖ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏™‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß: ${thaiTime}`);
    } catch (e) {
      console.error("auto-report error:", e);
    }
  }, Math.max(5 * 60 * 1000, minGapMs)); // ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏µ‡πà‡∏Å‡∏ß‡πà‡∏≤ minGapMs
}

// ===== Health & Root =====
app.get("/healthz", (_req, res) =>
  res.status(200).send("‚úÖ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö backend ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö ")
);

// ===== Root route (‡∏™‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
app.get("/", async (_req, res) => {
  let html = `‚úÖ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö backend ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö. <br>`;

  try {
    const sensor = await axios.get("https://ce395backend-1.onrender.com/latest");
    const { light, temp, humidity } = sensor.data;

    html = `
      ‚úÖ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö backend ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö. <br>
      üí° ‡∏Ñ‡πà‡∏≤‡πÅ‡∏™‡∏á: ${light} lux (${getLightStatus(light)}) <br>
      üå°Ô∏è ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: ${temp} ¬∞C (${getTempStatus(temp)}) <br>
      üíß ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: ${humidity} % (${getHumidityStatus(humidity)})
    `;
  } catch {
    if (lastSensorData) {
      html = `
        ‚úÖ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö backend ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö. <br>
      `;
    }
  }

  return res.send(html);
});

// ===== Start & graceful shutdown =====
const server = app.listen(PORT, () => {
  console.log(`üöÄ Server running at http://localhost:${PORT} (env: ${NODE_ENV})`);
});
process.on("SIGTERM", async () => {
  try {
    await prisma.$disconnect();
  } finally {
    server.close();
  }
});
process.on("SIGINT", async () => {
  try {
    await prisma.$disconnect();
  } finally {
    server.close();
  }
});
